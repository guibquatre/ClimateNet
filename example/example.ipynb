{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from climatenet.utils.data import ClimateDatasetLabeled, ClimateDataset\n",
    "from climatenet.models import CGNet\n",
    "from climatenet.utils.utils import Config\n",
    "from climatenet.track_events import track_events\n",
    "from climatenet.analyze_events import analyze_events\n",
    "from climatenet.visualize_events import visualize_events\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def save_submission(predictions):\n",
    "    with open('submission.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['SNo', 'Label'])\n",
    "        for idx, label in enumerate(predictions, 1):\n",
    "            writer.writerow([idx, label])\n",
    "\n",
    "\n",
    "def initialize_config(config_path):\n",
    "    try:\n",
    "        config = Config(config_path)\n",
    "        if 'architecture' in config and 'seed' in config:\n",
    "            print(\"Configurations initialized successfully.\")\n",
    "            return config\n",
    "    except Exception as e:\n",
    "        print(\"Initialization error: %s\" % e)\n",
    "        return None\n",
    "\n",
    "\n",
    "class ClimateAnalysisPipeline:\n",
    "    def __init__(self, config_path):\n",
    "        self.inference_set = None\n",
    "        self.training_set = None\n",
    "        self.config = initialize_config(config_path)\n",
    "        self.model = self.initialize_model()\n",
    "\n",
    "    def initialize_model(self):\n",
    "        if self.config:\n",
    "            try:\n",
    "                model = CGNet(self.config)\n",
    "                print(\"Model initialized successfully.\")\n",
    "                return model\n",
    "            except Exception as e:\n",
    "                print(\"Model initialization error: %s\" % e)\n",
    "        return None\n",
    "\n",
    "    def load_csv_datasets(self, training_csv_path, inference_csv_path, _default_config):\n",
    "        try:\n",
    "            self.training_set = ClimateDatasetLabeled(pd.read_csv(training_csv_path), _default_config)\n",
    "            self.inference_set = ClimateDataset(pd.read_csv(inference_csv_path), _default_config)\n",
    "            print(\"Datasets successfully loaded from CSV.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(\"CSV files are empty.\")\n",
    "        except pd.errors.ParserError:\n",
    "            print(\"Error while parsing CSV files.\")\n",
    "        except Exception as e:\n",
    "            print(\"Dataset loading error: %s\" % e)\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        self.train_model()\n",
    "        self.evaluate_baseline_models()\n",
    "        self.track_and_analyze_events()\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model.train(self.training_set)\n",
    "        print(\"Model trained.\")\n",
    "\n",
    "    def evaluate_baseline_models(self):\n",
    "        baseline_models = [\n",
    "            (DummyClassifier(strategy=\"uniform\"), \"Dummy Classifier\"),\n",
    "            (SGDClassifier(), \"Stochastic Gradient Descent\"),\n",
    "            (SVC(), \"Support Vector Machine\"),\n",
    "            (RandomForestClassifier(), \"Random Forest\"),\n",
    "            (LogisticRegression(max_iter=1000), \"Logistic Regression\"),\n",
    "        ]\n",
    "\n",
    "        for model, name in baseline_models:\n",
    "            self.evaluate_baseline(model, name)\n",
    "\n",
    "    def evaluate_baseline(self, model, model_name):\n",
    "        model.fit(self.training_set.data, self.training_set.labels)\n",
    "        predictions = model.predict(self.inference_set.data)\n",
    "        print(\"%s Performance\" % model_name)\n",
    "        print(classification_report(self.inference_set.labels, predictions))\n",
    "\n",
    "    def track_and_analyze_events(self):\n",
    "        if self.inference_set is not None:\n",
    "            class_masks = self.model.predict(self.inference_set)\n",
    "            event_masks = track_events(class_masks)\n",
    "            analyze_events(event_masks, class_masks, 'results/')\n",
    "            visualize_events(event_masks, self.inference_set, 'pngs/')\n",
    "        else:\n",
    "            print(\"Inference set is not available.\")\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        try:\n",
    "            self.model.save_model(save_path)\n",
    "            print(\"Model saved to %s\" % save_path)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to save the model: %s\" % e)\n",
    "\n",
    "    def visualize_with_seaborn(self):\n",
    "        sns.heatmap(self.inference_set.corr(), annot=True, fmt=\".2f\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Climate Analysis Pipeline')\n",
    "default_config = '/content/drive/MyDrive/climateDoc/model/config-init.json'\n",
    "default_train_csv = '/content/drive/MyDrive/climateDoc/classification-of-extreme-weather-events-udem/train.csv'\n",
    "default_infer_csv = '/content/drive/MyDrive/climateDoc/classification-of-extreme-weather-events-udem/test.csv'\n",
    "\n",
    "parser.add_argument('--config', type=str, default=default_config, help='Path to the config file')\n",
    "parser.add_argument('--train_csv', type=str, default=default_train_csv, help='Path to the training set CSV')\n",
    "parser.add_argument('--infer_csv', type=str, default=default_infer_csv, help='Path to the inference set CSV')\n",
    "parser.add_argument('--save', type=str, required=False, help='models/')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "pipeline = ClimateAnalysisPipeline(args.config)\n",
    "pipeline.load_csv_datasets(args.train_csv, args.infer_csv, default_config)\n",
    "pipeline.train_and_evaluate()\n",
    "\n",
    "if args.save:\n",
    "    pipeline.save_model(args.save)\n",
    "\n",
    "pipeline.visualize_with_seaborn()\n",
    "\n",
    "print(\"Climate Analysis Pipeline execution complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
